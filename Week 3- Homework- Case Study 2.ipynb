{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-mechanism",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case Study 2 Homework #############################################\n",
    "\n",
    "\n",
    "##################### Language Processing ###########################\n",
    "\n",
    "\n",
    "import os \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def count_words_fast(text): \n",
    "    text = text.lower() \n",
    "    skips = [\".\", \",\", \";\", \":\", \"'\", '\"', \"\\n\", \"!\", \"?\", \"(\", \")\"] \n",
    "    for ch in skips: \n",
    "        text = text.replace(ch, \"\") \n",
    "    word_counts = Counter(text.split(\" \")) \n",
    "    return word_counts\n",
    "\n",
    "def word_stats(word_counts): \n",
    "    num_unique = len(word_counts) \n",
    "    counts = word_counts.values() \n",
    "    return (num_unique, counts)\n",
    "\n",
    "##################################################################################################################\n",
    "\n",
    "# Exercise 1\n",
    "# In this case study, we will find and visualize summary statistics of the text of different translations of Hamlet. \n",
    "\n",
    "\n",
    "# Instructions\n",
    "# Read in the data as a pandas dataframe using pd.read_csv. Use the index_col argument to set the first column in \n",
    "# the csv file as the index for the dataframe. The data can be found at \n",
    "# https://courses.edx.org/asset-v1:HarvardX+PH526x+2T2019+type@asset+block@hamlets.csv\n",
    "\n",
    "file_loc = 'hamlets.csv'\n",
    "hamlets = pd.read_csv(file_loc, index_col=0)\n",
    "hamlets\n",
    "\n",
    "####################################################################################################################\n",
    "\n",
    "# Exercise 2\n",
    "#In this exercise, we will summarize the text for a single translation of Hamlet in a pandas dataframe.\n",
    "\n",
    "#Instructions\n",
    "#Find the dictionary of word frequency in text by calling count_words_fast(). Store this as counted_text.\n",
    "#Create a pandas dataframe named data.\n",
    "#Using counted_text, define two columns in data:\n",
    "#     word, consisting of each unique word in text.\n",
    "#     count, consisting of the number of times each word in word is included in the text.\n",
    "\n",
    "# Method - 1\n",
    "\n",
    "language, text = hamlets.iloc[0]\n",
    "counted_text = count_words_fast(text)\n",
    "data = pd.DataFrame({'word': list(counted_text.keys()),'count': list(counted_text.values())})\n",
    "\n",
    "    \n",
    "# Method-2\n",
    "\n",
    "#language, text = hamlets.iloc[0]\n",
    "#counted_text = count_words_fast(text)\n",
    "#data = pd.DataFrame(columns=('word', 'count'))\n",
    "#position = 0\n",
    "#for key, value in counted_text.items():\n",
    "#    data.loc[position]= key, value\n",
    "#    position += 1\n",
    "\n",
    "#####################################################################################################################\n",
    "\n",
    "# Exercise 3\n",
    "\n",
    "#In this exercise, we will continue to define summary statistics for a single translation of Hamlet.\n",
    "\n",
    "#Instructions\n",
    "#Add a column to data named length, defined as the length of each word.\n",
    "#Add another column named frequency, which is defined as follows for each word in data:\n",
    "#If count > 10, frequency is \"frequent\".\n",
    "#If 1 < count <= 10, frequency is \"infrequent\".\n",
    "#If count == 1, frequency is \"unique\".\n",
    "\n",
    "# Method - 1\n",
    "\n",
    "data[\"length\"] = data[\"word\"].apply(len)  # the length of each word will be assigned to a new column named length\n",
    "\n",
    "data.loc[data[\"count\"] > 10,  \"frequency\"] = \"frequent\"\n",
    "data.loc[data[\"count\"] <= 10, \"frequency\"] = \"infrequent\"\n",
    "data.loc[data[\"count\"] == 1,  \"frequency\"] = \"unique\"\n",
    "\n",
    "data.groupby('frequency').count()   # count the number of unique words appear within the column - frequency\n",
    "\n",
    "# Method 2 [ This method is based on for loop which may take more time than method-1. It means method-1 is more faster]\n",
    "\n",
    "#data['length'] = \"\"\n",
    "#data['frequency'] = \"\"\n",
    "#for ind in range(len(list(counted_text.keys()))):\n",
    "#    data.loc[ind, 'length'] = len(data.loc[ind, 'word'])\n",
    "#    if data.loc[ind, 'count'] > 10:\n",
    "#        data.loc[ind, 'frequency'] = \"frequent\"\n",
    "#    elif 1 < data.loc[ind, 'count'] <= 10:\n",
    "#        data.loc[ind, 'frequency'] = \"infrequent\"\n",
    "#    elif data.loc[ind, 'count'] == 1:\n",
    "#        data.loc[ind, 'frequency'] = \"unique\"\n",
    "\n",
    "#len(data[data['frequency'] == \"unique\"])  # to check how many times unique words appear in the text\n",
    "\n",
    "#####################################################################################################################\n",
    "\n",
    "# Exercise 4\n",
    "\n",
    "#In this exercise, we will summarize the statistics in data into a smaller pandas dataframe.\n",
    "\n",
    "#Instructions\n",
    "#Create a pandas dataframe named sub_data including the following columns:\n",
    "#language, which is the language of the text (defined in Exercise 2).\n",
    "#frequency, which is a list containing the strings \"frequent\", \"infrequent\", and \"unique\".\n",
    "#mean_word_length, which is the mean word length of each value in frequency.\n",
    "#num_words, which is the total number of words in each frequency category.\n",
    "\n",
    "#Method - 1\n",
    "\n",
    "sub_data = pd.DataFrame({\n",
    "    'language': language, \n",
    "    'frequency': [\"frequent\", \"infrequent\", \"unique\"], \n",
    "    'mean_word_length': data.groupby(by = \"frequency\",as_index=False)[\"length\"].mean().iloc[:,1], \n",
    "    'num_words': data.groupby(by = \"frequency\", as_index=False).size().iloc[:,1]\n",
    "    })\n",
    "sub_data\n",
    "\n",
    "\n",
    "# Method -2 \n",
    "\n",
    "#sub_data = pd.DataFrame({'language': language, 'frequency': [\"frequent\", \"infrequent\", \"unique\"], \n",
    "#                         'mean_word_length': '', \n",
    "#                         'num_words':''\n",
    "#                        })\n",
    "#frequency_test = [\"frequent\", \"infrequent\", \"unique\"]\n",
    "#for i in range(len(frequency_test)):\n",
    "#    sub_data.loc[i, 'mean_word_length'] = data[data['frequency']== frequency_test[i]].length.mean()\n",
    "#    sub_data.loc[i,'num_words'] = data.groupby('frequency').sum().loc[frequency_test[i],'count']\n",
    "#sub_data\n",
    "\n",
    "#####################################################################################################################\n",
    "\n",
    "# Exercise 5\n",
    "\n",
    "#In this exercise, we will join all the data summaries for text Hamlet translation.\n",
    "\n",
    "#Instructions\n",
    "#The previous code for summarizing a particular translation of Hamlet is consolidated into a single function called \n",
    "#summarize_text. Create a pandas dataframegrouped_data consisting of the results of summarize_text for each translation \n",
    "#of Hamlet in hamlets.\n",
    "#Use a for loop across the row indices of hamlets to assign each translation to a new row.\n",
    "#Obtain the ith row of hamlets to variables using the .iloc method, and assign the output to variables language and text.\n",
    "#Call summarize_text using language and text, and assign the output to sub_data.\n",
    "#Use the pandas .append() function to append to pandas dataframes row-wise to grouped_data\n",
    "\n",
    "def summarize_text(language, text):\n",
    "    counted_text = count_words_fast(text)\n",
    "\n",
    "    data = pd.DataFrame({\n",
    "        \"word\": list(counted_text.keys()),\n",
    "        \"count\": list(counted_text.values())\n",
    "    })\n",
    "    \n",
    "    data.loc[data[\"count\"] > 10,  \"frequency\"] = \"frequent\"\n",
    "    data.loc[data[\"count\"] <= 10, \"frequency\"] = \"infrequent\"\n",
    "    data.loc[data[\"count\"] == 1,  \"frequency\"] = \"unique\"\n",
    "    \n",
    "    data[\"length\"] = data[\"word\"].apply(len)\n",
    "    \n",
    "    sub_data = pd.DataFrame({\n",
    "        \"language\": language,\n",
    "        \"frequency\": [\"frequent\",\"infrequent\",\"unique\"],\n",
    "        \"mean_word_length\": data.groupby(by = \"frequency\")[\"length\"].mean(),\n",
    "        \"num_words\": data.groupby(by = \"frequency\").size()\n",
    "    })\n",
    "    \n",
    "    return(sub_data)\n",
    "\n",
    "\n",
    "grouped_data= pd.DataFrame([])\n",
    "for i in range(hamlets.shape[0]):\n",
    "    language, text = hamlets.iloc[i]\n",
    "    sub_data = summarize_text(language, text)\n",
    "    grouped_data = grouped_data.append(sub_data, ignore_index = True)\n",
    "\n",
    "######################################################################################################################\n",
    "\n",
    "#Exercise 6\n",
    "\n",
    "\n",
    "#In this exercise, we will plot our results and look for differences across each translation.\n",
    "\n",
    "#Instructions\n",
    "#Plot the word statistics of each translations on a single plot.\n",
    "#Consider: do the word statistics differ by translation?\n",
    "\n",
    "colors = {\"Portuguese\": \"green\", \"English\": \"blue\", \"German\": \"red\"}\n",
    "markers = {\"frequent\": \"o\",\"infrequent\": \"s\", \"unique\": \"^\"}\n",
    "import matplotlib.pyplot as plt\n",
    "for i in range(grouped_data.shape[0]):\n",
    "    row = grouped_data.iloc[i]\n",
    "    plt.plot(row.mean_word_length, row.num_words,\n",
    "        marker=markers[row.frequency],\n",
    "        color = colors[row.language],\n",
    "        markersize = 10\n",
    "    )\n",
    "\n",
    "color_legend = []\n",
    "marker_legend = []\n",
    "for color in colors:\n",
    "    color_legend.append(\n",
    "        plt.plot([], [],\n",
    "        color=colors[color],\n",
    "        marker=\"o\",\n",
    "        label = color, markersize = 10, linestyle=\"None\")\n",
    "    )\n",
    "for marker in markers:\n",
    "    marker_legend.append(\n",
    "        plt.plot([], [],\n",
    "        color=\"k\",\n",
    "        marker=markers[marker],\n",
    "        label = marker, markersize = 10, linestyle=\"None\")\n",
    "    )\n",
    "plt.legend(numpoints=1, loc = \"upper left\")\n",
    "\n",
    "plt.xlabel(\"Mean Word Length\")\n",
    "plt.ylabel(\"Number of Words\")\n",
    "plt.show()\n",
    "\n",
    "# we observe that unique word category differ the statistics most by translation.\n",
    "# The course link - https://learning.edx.org/course/course-v1:HarvardX+PH526x+2T2020/home"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
